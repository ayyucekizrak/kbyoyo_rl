{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Approximation\n",
    "\n",
    "Bu Notebook, Cartpole probleminin lineer fonksiyon yakinsama ile cozumunu icermektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Stuff\n",
    "import gym\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "CSS = \"\"\"\n",
    ".output {\n",
    "    align-items: center;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "display.HTML('<style>{}</style>'.format(CSS))\n",
    "\n",
    "def show_state(env, e, t):\n",
    "    plt.figure(3, figsize=(10, 10))\n",
    "    plt.clf()\n",
    "    plt.imshow(env.render(mode='rgb_array'))\n",
    "    plt.title(\"Episode: {}, Step: {}\".format(e, t))\n",
    "    plt.axis('off')\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "n_episodes = 500\n",
    "gamma = 0.99\n",
    "epsilon = 0.2\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartpole\n",
    "\n",
    "Bir cubuk hareket edebilen bir araca serbest bir eklem ile baglidir. Bu arac, surtunmesiz bir ortamda saga sola hareket etmektedir ve yarattigi ivme cubugu ters yonde hareket ettirmektedir. Amacimiz, araci hareket saga ya da sola hareket ettirerek cubugun dusmesini engellemektir. Cubugun devrilmedigi her anda +1 odulu elde edilir eger cubuk 15 dereceden fazla aci yaparsa veya arac merkezden 2.4 unite uzaklasirsa episode biter.\n",
    "\n",
    "Bu problemde stateler sureklidir (continuous). Bu nedenle tablo olusturmak yerine stateleri Q degerlerine yansitacak parametreleri ogrenmemiz gerekmekte. Bu ornekte lineer bir sekilde bu fonksiyonu parametrize edecegiz.\n",
    "\n",
    "$$\n",
    "Q_W(s, .) = Ws\n",
    "$$\n",
    "\n",
    "Her iterasyon icin, policemizden bir aksiyon sececegiz ($\\epsilon$-greedy). Secilen aksiyona gore suan bulundugumuz satetin Q degerini gelecekte elde edilecek odulleri makzimize edecek sekilde guncelleyecegiz. Once TD hatasini (Temporal difference error) hesaplamamiz gerekmekte.\n",
    "\n",
    "$$\n",
    "\\delta = R + \\gamma Q_W(S', A') - Q_W(S, A)\n",
    "$$\n",
    "\n",
    "Bu hatayi minimize etmek istiyoruz. $W$ parametrelerini $-\\delta$'yi minimize edecek sekilde guncellemek icin, $Q$ degerlerinin secilen aksiyon icin  degisimi yonunde ilerlememiz gerekmektedir, bu bilgiyi de bize gradyan vermektedir.\n",
    "\n",
    "$$\n",
    "W \\leftarrow W + \\alpha\\delta\\nabla_WQ(S,A)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonksiyon parametrelerini olusturalim\n",
    "# State buyuklugu 4, aksiyon sayisi 2\n",
    "W = np.zeros((2, 4))\n",
    "\n",
    "# Q Fonksiyonu\n",
    "def f(W, s):\n",
    "    return np.matmul(W, s)\n",
    "\n",
    "# Verilen bir aksiyonun Q degeri\n",
    "def q(W, s, a):\n",
    "    return f(W, s)[a]\n",
    "\n",
    "# Q degerinin parametrelere gore gradyani\n",
    "def dq(W, s, a):\n",
    "    d = np.zeros_like(W)\n",
    "    d[a] = s\n",
    "    return d\n",
    "\n",
    "# epsilon-greedy policesi\n",
    "def policy(W, s, eps=None):\n",
    "    if eps:\n",
    "        nA = W.shape[0]\n",
    "        if np.random.rand() < eps:\n",
    "            return np.random.randint(nA)\n",
    "    return np.argmax(f(W, s))\n",
    "\n",
    "# Greedy police kullanan fonksiyon\n",
    "def run_env(env, W):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    t = 0\n",
    "\n",
    "    while not done:\n",
    "        t += 1\n",
    "        show_state(env, 1, t)\n",
    "\n",
    "        action = policy(W, state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Egitilmemis\n",
    "env = gym.make('CartPole-v0')\n",
    "run_env(env, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = []\n",
    "W = np.zeros((2, 4))\n",
    "\n",
    "# Her bir episode icin\n",
    "for e in tqdm(range(1, n_episodes+1)):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    t = 0\n",
    "    total_reward = 0\n",
    "    \n",
    "    # Bitmedigi surece\n",
    "    while not done:\n",
    "        t += 1\n",
    "        \n",
    "        # Epsilon-greedy ile aksiyon sec\n",
    "        action = policy(W, state, epsilon)\n",
    "        # Aksiyon al\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        total_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            # Eger bitmisse sonraki aksionu dahil etme\n",
    "            W += alpha * (reward - q(W, state, action)) * dq(W, state, action)\n",
    "        else:\n",
    "            # Bitmemisse sonraki aksiyonu da dahil et\n",
    "            next_action = policy(W, next_state, epsilon)\n",
    "            diff = reward - gamma*q(W, next_state, next_action) - q(W, state, action)\n",
    "        \n",
    "            W += alpha * diff * dq(W, state, action)\n",
    "            \n",
    "        state = next_state\n",
    "       \n",
    "    rewards.append(total_reward)\n",
    "    \n",
    "    if e % 100 == 0:\n",
    "        epsilon /= 2.\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Egitildikten sonra\n",
    "run_env(env, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonuc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deadly triad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
